//! NVFBC-based screen capture service
//! 
//! High-performance screen capture using NVIDIA Frame Buffer Capture API.
//! Bypasses X11 completely and reads directly from GPU framebuffer.
//! 
//! ## Performance
//! - Captures at 50-60+ FPS on X11
//! - Near zero CPU overhead
//! - Works on GeForce, Quadro, Tesla GPUs

use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::time::Duration;
use anyhow::Result;
use nvfbc::{SystemCapturer, BufferFormat};
use nvfbc::system::CaptureMethod;
use livekit::webrtc::video_frame::{VideoFrame, I420Buffer};
use livekit::webrtc::video_source::native::NativeVideoSource;

/// Check if NVFBC is available on this system
pub fn is_nvfbc_available() -> bool {
    match SystemCapturer::new() {
        Ok(capturer) => {
            match capturer.status() {
                Ok(status) => status.can_create_now,
                Err(_) => false,
            }
        }
        Err(_) => false,
    }
}

/// NVFBC-based screen share service
pub struct NvfbcScreenShare {
    running: Arc<AtomicBool>,
    handle: Option<std::thread::JoinHandle<()>>,
}

impl NvfbcScreenShare {
    /// Create a new NVFBC screen share session
    /// 
    /// Returns an error if NVFBC is not available.
    pub fn new(
        source: Arc<NativeVideoSource>,
        target_fps: u32,
    ) -> Result<Self> {
        // Check availability first (on main thread)
        if !is_nvfbc_available() {
            return Err(anyhow::anyhow!("NVFBC is not available on this system"));
        }
        
        let running = Arc::new(AtomicBool::new(true));
        let running_clone = running.clone();
        let source_clone = source.clone();
        
        // Create capturer inside the thread since it's not Send
        let handle = std::thread::spawn(move || {
            // Create capturer in this thread
            let mut capturer = match SystemCapturer::new() {
                Ok(c) => c,
                Err(e) => {
                    eprintln!("âŒ NVFBC init failed in thread: {:?}", e);
                    return;
                }
            };
            
            let status = match capturer.status() {
                Ok(s) => s,
                Err(e) => {
                    eprintln!("âŒ NVFBC status failed: {:?}", e);
                    return;
                }
            };
            
            let width = status.screen_size.w;
            let height = status.screen_size.h;
            println!("ðŸ–¥ï¸  NVFBC: Screen {}x{} @ {} FPS target", width, height, target_fps);
            
            // Start capture
            if let Err(e) = capturer.start(BufferFormat::Bgra, target_fps) {
                eprintln!("âŒ NVFBC start failed: {:?}", e);
                return;
            }
            
            let mut frame_count = 0u64;
            let start = std::time::Instant::now();
            let frame_timeout = Some(Duration::from_millis(50));
            
            println!("âœ… NVFBC capture loop started");
            
            while running_clone.load(Ordering::Relaxed) {
                match capturer.next_frame(CaptureMethod::Blocking, frame_timeout) {
                    Ok(frame_info) => {
                        // Convert BGRA to I420 for LiveKit
                        let mut i420_buf = I420Buffer::new(frame_info.width, frame_info.height);
                        bgra_to_i420(frame_info.buffer, frame_info.width, frame_info.height, &mut i420_buf);
                        
                        // Create VideoFrame
                        let timestamp_us = std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap()
                            .as_micros() as i64;
                        
                        let mut video_frame = VideoFrame {
                            buffer: i420_buf,
                            timestamp_us,
                            rotation: livekit::webrtc::video_frame::VideoRotation::VideoRotation0,
                        };
                        
                        source_clone.capture_frame(&mut video_frame);
                        
                        frame_count += 1;
                        if frame_count % 300 == 0 {
                            let fps = frame_count as f64 / start.elapsed().as_secs_f64();
                            println!("ðŸ“¹ NVFBC: {} frames, {:.1} FPS avg", frame_count, fps);
                        }
                    }
                    Err(e) => {
                        // Timeout is OK, just continue
                        if !format!("{:?}", e).contains("Timeout") {
                            eprintln!("âš ï¸  NVFBC frame error: {:?}", e);
                        }
                    }
                }
            }
            
            let _ = capturer.stop();
            println!("ðŸ“¹ NVFBC: Session stopped");
        });
        
        Ok(Self { 
            running, 
            handle: Some(handle),
        })
    }
    
    /// Shutdown the screen share
    pub fn shutdown(mut self) {
        self.running.store(false, Ordering::Relaxed);
        if let Some(handle) = self.handle.take() {
            let _ = handle.join();
        }
    }
}

impl Drop for NvfbcScreenShare {
    fn drop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
        // Note: We can't join the thread in Drop as it might panic
    }
}

/// Convert BGRA to I420
fn bgra_to_i420(bgra: &[u8], width: u32, height: u32, i420: &mut I420Buffer) {
    let (y_plane, u_plane, v_plane) = i420.data_mut();
    
    let w = width as usize;
    let h = height as usize;
    
    // Process 2x2 blocks
    for j in 0..h/2 {
        for i in 0..w/2 {
            let mut r_sum = 0i32;
            let mut g_sum = 0i32;
            let mut b_sum = 0i32;
            
            for dy in 0..2 {
                for dx in 0..2 {
                    let px = i * 2 + dx;
                    let py = j * 2 + dy;
                    let idx = (py * w + px) * 4;
                    
                    if idx + 3 >= bgra.len() {
                        continue;
                    }
                    
                    let b = bgra[idx] as i32;
                    let g = bgra[idx + 1] as i32;
                    let r = bgra[idx + 2] as i32;
                    
                    let y = ((66 * r + 129 * g + 25 * b + 128) >> 8) + 16;
                    y_plane[py * w + px] = y.clamp(0, 255) as u8;
                    
                    r_sum += r;
                    g_sum += g;
                    b_sum += b;
                }
            }
            
            let r_avg = r_sum / 4;
            let g_avg = g_sum / 4;
            let b_avg = b_sum / 4;
            
            let u = ((-38 * r_avg - 74 * g_avg + 112 * b_avg + 128) >> 8) + 128;
            let v = ((112 * r_avg - 94 * g_avg - 18 * b_avg + 128) >> 8) + 128;
            
            let uv_idx = j * (w / 2) + i;
            if uv_idx < u_plane.len() {
                u_plane[uv_idx] = u.clamp(0, 255) as u8;
                v_plane[uv_idx] = v.clamp(0, 255) as u8;
            }
        }
    }
}
